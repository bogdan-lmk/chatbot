import os
import fitz  # PyMuPDF
from pathlib import Path
import argparse
from typing import List, Optional, Dict
import logging
import json
import time
from datetime import datetime
import concurrent.futures
from threading import Lock

class PDFToTextConverter:
    """
    –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–Ω–≤–µ—Ä—Ç–µ—Ä PDF —Ñ–∞–π–ª–æ–≤ –≤ —Ç–µ–∫—Å—Ç –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–æ 100 —Ñ–∞–π–ª–æ–≤
    """
    
    def __init__(self, output_format: str = "txt", max_workers: int = 4):
        """
        Args:
            output_format: "txt" –∏–ª–∏ "md" –¥–ª—è markdown
            max_workers: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Ç–æ–∫–æ–≤ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
        """
        self.output_format = output_format
        self.max_workers = max_workers
        self.processed_files = {}  # –ö—ç—à –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        self.lock = Lock()
        self.setup_logging()
        
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        self.cache_dir = Path("./pdf_cache")
        self.cache_dir.mkdir(exist_ok=True)
        
        self.load_cache()
    
    def setup_logging(self):
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('pdf_conversion.log'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
    
    def load_cache(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫—ç—à –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
        cache_file = self.cache_dir / "processed_cache.json"
        if cache_file.exists():
            try:
                with open(cache_file, 'r', encoding='utf-8') as f:
                    self.processed_files = json.load(f)
                self.logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω –∫—ç—à —Å {len(self.processed_files)} –∑–∞–ø–∏—Å—è–º–∏")
            except Exception as e:
                self.logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∫—ç—à: {e}")
                self.processed_files = {}
    
    def save_cache(self):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∫—ç—à –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
        cache_file = self.cache_dir / "processed_cache.json"
        try:
            with open(cache_file, 'w', encoding='utf-8') as f:
                json.dump(self.processed_files, f, ensure_ascii=False, indent=2)
        except Exception as e:
            self.logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∫—ç—à: {e}")
    
    def get_file_hash(self, file_path: str) -> str:
        """–°–æ–∑–¥–∞–µ—Ç —Ö—ç—à —Ñ–∞–π–ª–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–π"""
        stat = os.stat(file_path)
        return f"{stat.st_size}_{stat.st_mtime}"
    
    def is_file_processed(self, file_path: str, output_path: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –±—ã–ª –ª–∏ —Ñ–∞–π–ª —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω"""
        file_hash = self.get_file_hash(file_path)
        file_key = str(Path(file_path).absolute())
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
        if file_key in self.processed_files:
            cached_info = self.processed_files[file_key]
            if (cached_info.get("hash") == file_hash and 
                Path(output_path).exists()):
                return True
        
        return False
    
    def extract_text_from_pdf(self, pdf_path: str) -> Dict:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ PDF —Ñ–∞–π–ª–∞ —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        """
        try:
            doc = fitz.open(pdf_path)
            text_content = []
            metadata = {
                "total_pages": len(doc),
                "title": doc.metadata.get("title", ""),
                "author": doc.metadata.get("author", ""),
                "creation_date": doc.metadata.get("creationDate", ""),
                "page_texts": []
            }
            
            for page_num in range(len(doc)):
                page = doc.load_page(page_num)
                text = page.get_text("text")
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—Å—Ç –∫–∞–∂–¥–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã –æ—Ç–¥–µ–ª—å–Ω–æ
                metadata["page_texts"].append({
                    "page": page_num + 1,
                    "char_count": len(text),
                    "has_content": bool(text.strip())
                })
                
                if self.output_format == "md":
                    if page_num > 0:
                        text_content.append(f"\n\n---\n\n## –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num + 1}\n\n")
                    else:
                        text_content.append(f"# {Path(pdf_path).stem}\n\n## –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num + 1}\n\n")
                else:
                    if page_num > 0:
                        text_content.append(f"\n\n{'='*50}\n–°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num + 1}\n{'='*50}\n\n")
                
                # –û—á–∏—â–∞–µ–º –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç
                cleaned_text = self.clean_text(text)
                text_content.append(cleaned_text)
            
            doc.close()
            
            return {
                "text": "".join(text_content),
                "metadata": metadata,
                "success": True,
                "error": None
            }
            
        except Exception as e:
            return {
                "text": "",
                "metadata": {},
                "success": False,
                "error": str(e)
            }
    
    def clean_text(self, text: str) -> str:
        """–û—á–∏—â–∞–µ—Ç –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç"""
        lines = text.split('\n')
        cleaned_lines = []
        
        for line in lines:
            # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
            line = line.strip()
            if line:
                cleaned_lines.append(line)
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ –¥–ª—è —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –∞–±–∑–∞—Ü–µ–≤
            elif cleaned_lines and cleaned_lines[-1] != "":
                cleaned_lines.append("")
        
        return '\n'.join(cleaned_lines)
    
    def convert_single_file(self, input_path: str, output_dir: str) -> Dict:
        """
        –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –æ–¥–∏–Ω PDF —Ñ–∞–π–ª —Å –ø–æ–¥—Ä–æ–±–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
        """
        try:
            input_file = Path(input_path)
            output_dir = Path(output_dir)
            output_dir.mkdir(parents=True, exist_ok=True)
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –∏–º—è –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
            output_extension = ".md" if self.output_format == "md" else ".txt"
            output_file = output_dir / f"{input_file.stem}{output_extension}"
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
            if self.is_file_processed(input_path, str(output_file)):
                self.logger.info(f"‚è© –ü—Ä–æ–ø—É—Å–∫ (—É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω): {input_file.name}")
                return {
                    "status": "skipped",
                    "input_file": str(input_file),
                    "output_file": str(output_file),
                    "reason": "already_processed"
                }
            
            self.logger.info(f"üîÑ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º: {input_file.name}")
            start_time = time.time()
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç
            result = self.extract_text_from_pdf(input_path)
            
            if not result["success"]:
                return {
                    "status": "error",
                    "input_file": str(input_file),
                    "output_file": str(output_file),
                    "error": result["error"]
                }
            
            if not result["text"].strip():
                self.logger.warning(f"‚ö†Ô∏è  –ü—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {input_file.name}")
                return {
                    "status": "empty",
                    "input_file": str(input_file),
                    "output_file": str(output_file),
                    "metadata": result["metadata"]
                }
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—Å—Ç
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(result["text"])
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            metadata_file = output_dir / f"{input_file.stem}_metadata.json"
            with open(metadata_file, 'w', encoding='utf-8') as f:
                json.dump(result["metadata"], f, ensure_ascii=False, indent=2)
            
            processing_time = time.time() - start_time
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –∫—ç—à
            with self.lock:
                file_key = str(Path(input_path).absolute())
                self.processed_files[file_key] = {
                    "hash": self.get_file_hash(input_path),
                    "processed_at": datetime.now().isoformat(),
                    "output_file": str(output_file),
                    "processing_time": processing_time,
                    "pages": result["metadata"]["total_pages"]
                }
            
            self.logger.info(f"‚úÖ –ì–æ—Ç–æ–≤–æ: {input_file.name} ({processing_time:.2f}s)")
            
            return {
                "status": "success",
                "input_file": str(input_file),
                "output_file": str(output_file),
                "metadata": result["metadata"],
                "processing_time": processing_time
            }
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ {input_path}: {str(e)}")
            return {
                "status": "error",
                "input_file": str(input_path),
                "error": str(e)
            }
    
    def convert_batch(self, input_dir: str, output_dir: str, 
                     file_pattern: str = "*.pdf", parallel: bool = True) -> Dict:
        """
        –ú–∞—Å—Å–æ–≤–∞—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —Å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π
        """
        input_path = Path(input_dir)
        results = {
            "success": 0, 
            "failed": 0, 
            "skipped": 0,
            "empty": 0,
            "files": [],
            "total_time": 0,
            "start_time": datetime.now().isoformat()
        }
        
        # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ PDF —Ñ–∞–π–ª—ã
        pdf_files = list(input_path.glob(file_pattern))
        
        if not pdf_files:
            self.logger.warning(f"PDF —Ñ–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ {input_dir}")
            return results
        
        self.logger.info(f"üîç –ù–∞–π–¥–µ–Ω–æ {len(pdf_files)} PDF —Ñ–∞–π–ª–æ–≤")
        start_time = time.time()
        
        if parallel and len(pdf_files) > 1:
            # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
            with concurrent.futures.ThreadPoolExecutor(max_workers=self.max_workers) as executor:
                future_to_file = {
                    executor.submit(self.convert_single_file, str(pdf_file), output_dir): pdf_file 
                    for pdf_file in pdf_files
                }
                
                for future in concurrent.futures.as_completed(future_to_file):
                    result = future.result()
                    self._update_results(results, result)
        else:
            # –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
            for pdf_file in pdf_files:
                result = self.convert_single_file(str(pdf_file), output_dir)
                self._update_results(results, result)
        
        results["total_time"] = time.time() - start_time
        results["end_time"] = datetime.now().isoformat()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫—ç—à
        self.save_cache()
        
        return results
    
    def _update_results(self, results: Dict, result: Dict):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        results["files"].append(result)
        
        if result["status"] == "success":
            results["success"] += 1
        elif result["status"] == "error":
            results["failed"] += 1
        elif result["status"] == "skipped":
            results["skipped"] += 1
        elif result["status"] == "empty":
            results["empty"] += 1
    
    def generate_report(self, results: Dict, output_dir: str):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç—á–µ—Ç –æ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏"""
        report_file = Path(output_dir) / "conversion_report.json"
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å–≤–æ–¥–∫—É
        results["summary"] = {
            "total_files": len(results["files"]),
            "success_rate": results["success"] / max(len(results["files"]), 1) * 100,
            "avg_time_per_file": results["total_time"] / max(len(results["files"]), 1)
        }
        
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —á–∏—Ç–∞–µ–º—ã–π –æ—Ç—á–µ—Ç
        readable_report = Path(output_dir) / "conversion_report.txt"
        with open(readable_report, 'w', encoding='utf-8') as f:
            f.write("–û–¢–ß–ï–¢ –û –ö–û–ù–í–ï–†–¢–ê–¶–ò–ò PDF\n")
            f.write("=" * 50 + "\n\n")
            f.write(f"–î–∞—Ç–∞: {results['start_time']}\n")
            f.write(f"–û–±—â–µ–µ –≤—Ä–µ–º—è: {results['total_time']:.2f} —Å–µ–∫—É–Ω–¥\n")
            f.write(f"–§–∞–π–ª–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {len(results['files'])}\n")
            f.write(f"–£—Å–ø–µ—à–Ω–æ: {results['success']}\n")
            f.write(f"–û—à–∏–±–∫–∏: {results['failed']}\n")
            f.write(f"–ü—Ä–æ–ø—É—â–µ–Ω–æ: {results['skipped']}\n")
            f.write(f"–ü—É—Å—Ç—ã–µ: {results['empty']}\n")
            f.write(f"–ü—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—Ö–∞: {results['summary']['success_rate']:.1f}%\n\n")
            
            if results["failed"] > 0:
                f.write("–§–ê–ô–õ–´ –° –û–®–ò–ë–ö–ê–ú–ò:\n")
                f.write("-" * 30 + "\n")
                for file_result in results["files"]:
                    if file_result["status"] == "error":
                        f.write(f"‚ùå {Path(file_result['input_file']).name}: {file_result.get('error', 'Unknown error')}\n")
                f.write("\n")
        
        self.logger.info(f"üìä –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {report_file}")


def main():
    parser = argparse.ArgumentParser(description='–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–Ω–≤–µ—Ä—Ç–µ—Ä PDF –≤ —Ç–µ–∫—Å—Ç')
    parser.add_argument('input', help='–ü—É—Ç—å –∫ PDF —Ñ–∞–π–ª—É –∏–ª–∏ –ø–∞–ø–∫–µ —Å PDF —Ñ–∞–π–ª–∞–º–∏')
    parser.add_argument('-o', '--output', default='./output', 
                       help='–ü–∞–ø–∫–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤')
    parser.add_argument('-f', '--format', choices=['txt', 'md'], default='txt',
                       help='–§–æ—Ä–º–∞—Ç –≤—ã–≤–æ–¥–∞: txt –∏–ª–∏ md')
    parser.add_argument('-w', '--workers', type=int, default=4,
                       help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Ç–æ–∫–æ–≤ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏')
    parser.add_argument('--no-parallel', action='store_true',
                       help='–û—Ç–∫–ª—é—á–∏—Ç—å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É')
    parser.add_argument('--info', action='store_true', 
                       help='–ü–æ–∫–∞–∑–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ PDF —Ñ–∞–π–ª–µ(–∞—Ö)')
    parser.add_argument('--clear-cache', action='store_true',
                       help='–û—á–∏—Å—Ç–∏—Ç—å –∫—ç—à –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤')
    
    args = parser.parse_args()
    
    converter = PDFToTextConverter(
        output_format=args.format,
        max_workers=args.workers
    )
    
    if args.clear_cache:
        cache_file = Path("./pdf_cache/processed_cache.json")
        if cache_file.exists():
            cache_file.unlink()
            print("üóëÔ∏è  –ö—ç—à –æ—á–∏—â–µ–Ω")
        return
    
    input_path = Path(args.input)
    
    if input_path.is_file():
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
        result = converter.convert_single_file(str(input_path), args.output)
        if result["status"] == "success":
            print(f"‚úÖ –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {result['output_file']}")
        else:
            print(f"‚ùå –û—à–∏–±–∫–∞: {result.get('error', 'Unknown error')}")
    
    elif input_path.is_dir():
        # –ú–∞—Å—Å–æ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
        print(f"üöÄ –ù–∞—á–∏–Ω–∞–µ–º –º–∞—Å—Å–æ–≤—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É...")
        results = converter.convert_batch(
            str(input_path), 
            args.output,
            parallel=not args.no_parallel
        )
        
        # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        print(f"\nüìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ö–û–ù–í–ï–†–¢–ê–¶–ò–ò:")
        print(f"=" * 40)
        print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ: {results['success']}")
        print(f"‚ùå –û—à–∏–±–∫–∏: {results['failed']}")
        print(f"‚è© –ü—Ä–æ–ø—É—â–µ–Ω–æ: {results['skipped']}")
        print(f"‚ö†Ô∏è  –ü—É—Å—Ç—ã–µ: {results['empty']}")
        print(f"‚è±Ô∏è  –í—Ä–µ–º—è: {results['total_time']:.2f} —Å–µ–∫")
        print(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã: {args.output}")
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç
        converter.generate_report(results, args.output)
    
    else:
        print(f"‚ùå –ü—É—Ç—å {input_path} –Ω–µ –Ω–∞–π–¥–µ–Ω")


if __name__ == "__main__":
    main()