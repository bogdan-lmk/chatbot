#!/usr/bin/env python3
# scripts/ingest.py

import os
from pathlib import Path
from langchain_community.document_loaders import TextLoader, PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from dotenv import load_dotenv

def load_documents(folder_path: Path):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ –ø–∞–ø–∫–∏"""
    docs = []
    supported_extensions = {'.pdf', '.txt', '.md'}
    
    print(f"üîç –°–∫–∞–Ω–∏—Ä—É–µ–º –ø–∞–ø–∫—É: {folder_path}")
    
    for file in folder_path.glob("*"):
        if file.suffix.lower() in supported_extensions:
            print(f"üìÑ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º: {file.name}")
            try:
                if file.suffix.lower() == ".pdf":
                    loader = PyPDFLoader(str(file))
                else:
                    loader = TextLoader(str(file), encoding="utf-8")
                file_docs = loader.load()
                docs.extend(file_docs)
                print(f"  ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(file_docs)} —á–∞—Å—Ç–µ–π")
            except Exception as e:
                print(f"  ‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {file.name}: {e}")
                continue
        else:
            print(f"  ‚è© –ü—Ä–æ–ø—É—Å–∫–∞–µ–º {file.name} (–Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç)")
    
    return docs

def main():
    print("üöÄ –°–û–ó–î–ê–ù–ò–ï FAISS –ò–ù–î–ï–ö–°–ê –î–õ–Ø –î–û–ö–£–ú–ï–ù–¢–û–í")
    print("="*50)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
    load_dotenv()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º API –∫–ª—é—á
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("‚ùå OPENAI_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è")
        print("üí° –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª .env —Å–æ–¥–µ—Ä–∂–∏—Ç:")
        print("   OPENAI_API_KEY=–≤–∞—à_–∫–ª—é—á_–∑–¥–µ—Å—å")
        return
    
    print(f"‚úÖ API –∫–ª—é—á –Ω–∞–π–¥–µ–Ω: {api_key[:15]}...")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞–ø–∫—É —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏
    docs_folder = Path("data/docs")
    if not docs_folder.exists():
        print(f"‚ùå –ü–∞–ø–∫–∞ {docs_folder} –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
        print(f"üí° –°–æ–∑–¥–∞–π—Ç–µ –ø–∞–ø–∫—É –∏ –ø–æ–º–µ—Å—Ç–∏—Ç–µ —Ç—É–¥–∞ –≤–∞—à–∏ PDF/TXT —Ñ–∞–π–ª—ã:")
        print(f"   mkdir -p {docs_folder}")
        return
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã
    docs = load_documents(docs_folder)
    
    if not docs:
        print("‚ùå –î–æ–∫—É–º–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        print(f"üí° –ü–æ–º–µ—Å—Ç–∏—Ç–µ PDF –∏–ª–∏ TXT —Ñ–∞–π–ª—ã –≤ –ø–∞–ø–∫—É {docs_folder}")
        return
    
    print(f"\nüìö –ù–∞–π–¥–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(docs)}")
    
    # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —á–∞—Å—Ç–∏
    print("‚úÇÔ∏è –†–∞–∑–±–∏–≤–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã –Ω–∞ —á–∞—Å—Ç–∏...")
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000, 
        chunk_overlap=200,
        length_function=len,
    )
    texts = splitter.split_documents(docs)
    print(f"üìù –°–æ–∑–¥–∞–Ω–æ —á–∞—Å—Ç–µ–π: {len(texts)}")
    
    # –°–æ–∑–¥–∞–µ–º embeddings
    print("üîß –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º OpenAI Embeddings...")
    embeddings = OpenAIEmbeddings(
        openai_api_key=api_key,
        model="text-embedding-ada-002"
    )
    
    # –°–æ–∑–¥–∞–µ–º FAISS –∏–Ω–¥–µ–∫—Å –ø–æ —á–∞—Å—Ç—è–º
    print("üîÑ –°–æ–∑–¥–∞–µ–º FAISS –∏–Ω–¥–µ–∫—Å...")
    index_path = Path("data/faiss_index")
    
    batch_size = 50  # –£–º–µ–Ω—å—à–µ–Ω–Ω—ã–π —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
    vectorstore = None
    
    total_batches = (len(texts) + batch_size - 1) // batch_size
    
    for i in range(0, len(texts), batch_size):
        batch_num = i // batch_size + 1
        batch = texts[i:i+batch_size]
        
        print(f"  üì¶ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á {batch_num}/{total_batches} ({len(batch)} —á–∞—Å—Ç–µ–π)...")
        
        try:
            if vectorstore is None:
                vectorstore = FAISS.from_documents(batch, embeddings)
                print(f"    ‚úÖ –°–æ–∑–¥–∞–Ω –±–∞–∑–æ–≤—ã–π –∏–Ω–¥–µ–∫—Å")
            else:
                vectorstore.add_documents(batch)
                print(f"    ‚úÖ –î–æ–±–∞–≤–ª–µ–Ω –±–∞—Ç—á –≤ –∏–Ω–¥–µ–∫—Å")
                
        except Exception as e:
            print(f"    ‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –±–∞—Ç—á–∞ {batch_num}: {e}")
            continue
    
    if vectorstore is None:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ")
        return
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω–¥–µ–∫—Å
    print("üíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º FAISS –∏–Ω–¥–µ–∫—Å...")
    index_path.mkdir(parents=True, exist_ok=True)
    vectorstore.save_local(str(index_path))
    
    print(f"\nüéâ –£–°–ü–ï–®–ù–û –ó–ê–í–ï–†–®–ï–ù–û!")
    print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    print(f"  ‚Ä¢ –î–æ–∫—É–º–µ–Ω—Ç–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {len(docs)}")
    print(f"  ‚Ä¢ –ß–∞—Å—Ç–µ–π —Å–æ–∑–¥–∞–Ω–æ: {len(texts)}")
    print(f"  ‚Ä¢ –ò–Ω–¥–µ–∫—Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {index_path}")
    print(f"\nüí° –¢–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ –∑–∞–ø—É—Å–∫–∞—Ç—å –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ: uvicorn src.app.main:app --reload")

if __name__ == "__main__":
    main()