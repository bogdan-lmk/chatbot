#!/usr/bin/env python3
# test_openai.py
"""
–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π —Ç–µ—Å—Ç–æ–≤—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ OpenAI API
"""

import os
import sys
import time
from datetime import datetime
from dotenv import load_dotenv
import traceback

def print_section(title):
    """–ö—Ä–∞—Å–∏–≤—ã–π –≤—ã–≤–æ–¥ —Å–µ–∫—Ü–∏–∏"""
    print(f"\n{'='*60}")
    print(f"  {title}")
    print(f"{'='*60}")

def print_status(message, status="info"):
    """–í—ã–≤–æ–¥ —Å —Å—Ç–∞—Ç—É—Å–æ–º"""
    icons = {
        "success": "‚úÖ",
        "error": "‚ùå",
        "warning": "‚ö†Ô∏è",
        "info": "‚ÑπÔ∏è",
        "loading": "üîÑ"
    }
    print(f"{icons.get(status, '‚ÑπÔ∏è')} {message}")

def test_environment():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö"""
    print_section("–ü–†–û–í–ï–†–ö–ê –û–ö–†–£–ñ–ï–ù–ò–Ø")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º .env
    load_dotenv()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ .env —Ñ–∞–π–ª–∞
    env_file = ".env"
    if os.path.exists(env_file):
        print_status(f"–§–∞–π–ª {env_file} –Ω–∞–π–¥–µ–Ω", "success")
    else:
        print_status(f"–§–∞–π–ª {env_file} –Ω–µ –Ω–∞–π–¥–µ–Ω", "warning")
        print("  –°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª .env —Å —Å–æ–¥–µ—Ä–∂–∏–º—ã–º:")
        print("  OPENAI_API_KEY=–≤–∞—à_–∫–ª—é—á_–∑–¥–µ—Å—å")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º API –∫–ª—é—á
    api_key = os.getenv("OPENAI_API_KEY")
    if api_key:
        print_status("API –∫–ª—é—á –Ω–∞–π–¥–µ–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è", "success")
        print(f"  –¢–∏–ø –∫–ª—é—á–∞: {api_key.split('-')[1] if '-' in api_key else 'unknown'}")
        print(f"  –î–ª–∏–Ω–∞: {len(api_key)} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"  –ù–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å: {api_key[:15]}...")
        print(f"  –ó–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è –Ω–∞: ...{api_key[-10:]}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–æ—Ä–º–∞—Ç –∫–ª—é—á–∞
        if api_key.startswith('sk-'):
            if api_key.startswith('sk-proj-'):
                print_status("–§–æ—Ä–º–∞—Ç –∫–ª—é—á–∞: –Ω–æ–≤—ã–π –ø—Ä–æ–µ–∫—Ç–Ω—ã–π –∫–ª—é—á", "success")
            else:
                print_status("–§–æ—Ä–º–∞—Ç –∫–ª—é—á–∞: —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –∫–ª—é—á", "success")
        else:
            print_status("–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –∫–ª—é—á–∞ (–¥–æ–ª–∂–µ–Ω –Ω–∞—á–∏–Ω–∞—Ç—å—Å—è —Å 'sk-')", "error")
            return None
            
        return api_key
    else:
        print_status("API –∫–ª—é—á –Ω–µ –Ω–∞–π–¥–µ–Ω", "error")
        print("  –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ:")
        print("  1. –§–∞–π–ª .env —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
        print("  2. –í –Ω–µ–º –µ—Å—Ç—å —Å—Ç—Ä–æ–∫–∞ OPENAI_API_KEY=–≤–∞—à_–∫–ª—é—á")
        print("  3. –ö–ª—é—á –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤")
        return None

def test_openai_import():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ OpenAI"""
    print_section("–ü–†–û–í–ï–†–ö–ê –ë–ò–ë–õ–ò–û–¢–ï–ö")
    
    try:
        import openai
        print_status(f"openai –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω —É—Å–ø–µ—à–Ω–æ (–≤–µ—Ä—Å–∏—è: {openai.__version__})", "success")
        return True
    except ImportError as e:
        print_status(f"–û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ openai: {e}", "error")
        print("  –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –±–∏–±–ª–∏–æ—Ç–µ–∫—É: pip install openai>=1.0.0")
        return False
    except Exception as e:
        print_status(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∏–º–ø–æ—Ä—Ç–µ: {e}", "error")
        return False

def test_basic_api_call(api_key):
    """–ë–∞–∑–æ–≤—ã–π —Ç–µ—Å—Ç API"""
    print_section("–ë–ê–ó–û–í–´–ô –¢–ï–°–¢ API")
    
    try:
        from openai import OpenAI
        
        client = OpenAI(api_key=api_key)
        print_status("OpenAI –∫–ª–∏–µ–Ω—Ç —Å–æ–∑–¥–∞–Ω", "success")
        
        print_status("–û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å...", "loading")
        start_time = time.time()
        
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "user", "content": "–ü—Ä–∏–≤–µ—Ç! –°–∫–∞–∂–∏ –æ–¥–Ω–æ —Å–ª–æ–≤–æ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ."}
            ],
            max_tokens=10,
            temperature=0.5
        )
        
        end_time = time.time()
        response_time = end_time - start_time
        
        print_status("API –∑–∞–ø—Ä–æ—Å –≤—ã–ø–æ–ª–Ω–µ–Ω —É—Å–ø–µ—à–Ω–æ!", "success")
        print(f"  –í—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞: {response_time:.2f} —Å–µ–∫—É–Ω–¥")
        print(f"  –ú–æ–¥–µ–ª—å: {response.model}")
        print(f"  –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤: {response.usage.total_tokens}")
        print(f"  –û—Ç–≤–µ—Ç: '{response.choices[0].message.content.strip()}'")
        
        return True
        
    except Exception as e:
        print_status(f"–û—à–∏–±–∫–∞ API –∑–∞–ø—Ä–æ—Å–∞: {e}", "error")
        print(f"  –¢–∏–ø –æ—à–∏–±–∫–∏: {type(e).__name__}")
        if hasattr(e, 'status_code'):
            print(f"  HTTP –∫–æ–¥: {e.status_code}")
        return False

def test_models_availability(api_key):
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
    print_section("–ü–†–û–í–ï–†–ö–ê –î–û–°–¢–£–ü–ù–´–• –ú–û–î–ï–õ–ï–ô")
    
    try:
        from openai import OpenAI
        client = OpenAI(api_key=api_key)
        
        print_status("–ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π...", "loading")
        models = client.models.list()
        
        gpt_models = [m for m in models.data if 'gpt' in m.id.lower()]
        embedding_models = [m for m in models.data if 'embedding' in m.id.lower()]
        
        print_status(f"–ù–∞–π–¥–µ–Ω–æ {len(models.data)} –º–æ–¥–µ–ª–µ–π –≤—Å–µ–≥–æ", "success")
        print(f"  GPT –º–æ–¥–µ–ª–µ–π: {len(gpt_models)}")
        print(f"  Embedding –º–æ–¥–µ–ª–µ–π: {len(embedding_models)}")
        
        print("\n  –î–æ—Å—Ç—É–ø–Ω—ã–µ GPT –º–æ–¥–µ–ª–∏:")
        for model in sorted(gpt_models, key=lambda x: x.id)[:10]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 10
            print(f"    - {model.id}")
        
        return True
        
    except Exception as e:
        print_status(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π: {e}", "error")
        return False

def test_embeddings(api_key):
    """–¢–µ—Å—Ç embedding API"""
    print_section("–¢–ï–°–¢ EMBEDDINGS")
    
    try:
        from openai import OpenAI
        client = OpenAI(api_key=api_key)
        
        print_status("–¢–µ—Å—Ç–∏—Ä—É–µ–º embedding API...", "loading")
        start_time = time.time()
        
        response = client.embeddings.create(
            model="text-embedding-ada-002",
            input="–¢–µ—Å—Ç–æ–≤—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞"
        )
        
        end_time = time.time()
        response_time = end_time - start_time
        
        embedding = response.data[0].embedding
        
        print_status("Embeddings API —Ä–∞–±–æ—Ç–∞–µ—Ç!", "success")
        print(f"  –í—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞: {response_time:.2f} —Å–µ–∫—É–Ω–¥")
        print(f"  –†–∞–∑–º–µ—Ä –≤–µ–∫—Ç–æ—Ä–∞: {len(embedding)}")
        print(f"  –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤: {response.usage.total_tokens}")
        print(f"  –ü–µ—Ä–≤—ã–µ 5 –∑–Ω–∞—á–µ–Ω–∏–π: {embedding[:5]}")
        
        return True
        
    except Exception as e:
        print_status(f"–û—à–∏–±–∫–∞ Embeddings API: {e}", "error")
        return False

def test_rate_limits(api_key):
    """–¢–µ—Å—Ç –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π —Å–∫–æ—Ä–æ—Å—Ç–∏"""
    print_section("–¢–ï–°–¢ –õ–ò–ú–ò–¢–û–í –°–ö–û–†–û–°–¢–ò")
    
    try:
        from openai import OpenAI
        client = OpenAI(api_key=api_key)
        
        print_status("–û—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –±—ã—Å—Ç—Ä—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤...", "loading")
        
        requests_count = 3
        successful_requests = 0
        
        for i in range(requests_count):
            try:
                response = client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[{"role": "user", "content": f"–¢–µ—Å—Ç {i+1}"}],
                    max_tokens=5
                )
                successful_requests += 1
                print(f"  –ó–∞–ø—Ä–æ—Å {i+1}: ‚úÖ")
                time.sleep(0.5)  # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞
                
            except Exception as e:
                print(f"  –ó–∞–ø—Ä–æ—Å {i+1}: ‚ùå {e}")
        
        print_status(f"–£—Å–ø–µ—à–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤: {successful_requests}/{requests_count}", 
                    "success" if successful_requests == requests_count else "warning")
        
        return successful_requests > 0
        
    except Exception as e:
        print_status(f"–û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∞ –ª–∏–º–∏—Ç–æ–≤: {e}", "error")
        return False

def test_langchain_integration(api_key):
    """–¢–µ—Å—Ç –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å LangChain"""
    print_section("–¢–ï–°–¢ –ò–ù–¢–ï–ì–†–ê–¶–ò–ò –° LANGCHAIN")
    
    try:
        from langchain_openai import OpenAIEmbeddings, ChatOpenAI
        
        print_status("–¢–µ—Å—Ç–∏—Ä—É–µ–º LangChain OpenAI –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é...", "loading")
        
        # –¢–µ—Å—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        embeddings = OpenAIEmbeddings(
            openai_api_key=api_key,
            model="text-embedding-ada-002"
        )
        
        test_texts = ["–ü—Ä–∏–≤–µ—Ç –º–∏—Ä", "Hello world"]
        embedding_result = embeddings.embed_documents(test_texts)
        
        print_status("LangChain embeddings —Ä–∞–±–æ—Ç–∞—é—Ç!", "success")
        print(f"  –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ç–µ–∫—Å—Ç–æ–≤: {len(test_texts)}")
        print(f"  –†–∞–∑–º–µ—Ä –∫–∞–∂–¥–æ–≥–æ –≤–µ–∫—Ç–æ—Ä–∞: {len(embedding_result[0])}")
        
        # –¢–µ—Å—Ç —á–∞—Ç–∞
        chat = ChatOpenAI(
            openai_api_key=api_key,
            model="gpt-3.5-turbo",
            temperature=0
        )
        
        from langchain.schema import HumanMessage
        response = chat([HumanMessage(content="–°–∫–∞–∂–∏ '—Ç–µ—Å—Ç –ø—Ä–æ—à–µ–ª —É—Å–ø–µ—à–Ω–æ'")])
        
        print_status("LangChain chat —Ä–∞–±–æ—Ç–∞–µ—Ç!", "success")
        print(f"  –û—Ç–≤–µ—Ç: '{response.content}'")
        
        return True
        
    except ImportError as e:
        print_status(f"LangChain –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: {e}", "warning")
        print("  –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install langchain-openai")
        return False
    except Exception as e:
        print_status(f"–û—à–∏–±–∫–∞ LangChain –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏: {e}", "error")
        return False

def generate_report(results):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏—Ç–æ–≥–æ–≤–æ–≥–æ –æ—Ç—á–µ—Ç–∞"""
    print_section("–ò–¢–û–ì–û–í–´–ô –û–¢–ß–ï–¢")
    
    total_tests = len(results)
    passed_tests = sum(1 for result in results.values() if result)
    
    print(f"üìä –¢–µ—Å—Ç–æ–≤ –ø—Ä–æ–π–¥–µ–Ω–æ: {passed_tests}/{total_tests}")
    print(f"üìà –£—Å–ø–µ—à–Ω–æ—Å—Ç—å: {passed_tests/total_tests*100:.1f}%")
    print(f"‚è∞ –í—Ä–µ–º—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    print("\nüìã –î–µ—Ç–∞–ª–∏:")
    for test_name, result in results.items():
        status = "‚úÖ –ü–†–û–®–ï–õ" if result else "‚ùå –ü–†–û–í–ê–õ–ï–ù"
        print(f"  {test_name}: {status}")
    
    if passed_tests == total_tests:
        print_status("üéâ –í–°–ï –¢–ï–°–¢–´ –ü–†–û–ô–î–ï–ù–´! OpenAI API –≥–æ—Ç–æ–≤ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é", "success")
    elif passed_tests > 0:
        print_status("‚ö†Ô∏è –ß–∞—Å—Ç–∏—á–Ω–∞—è —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–æ–≤–∞–ª–µ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã", "warning")
    else:
        print_status("‚ùå API –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–ª—é—á –∏ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ", "error")
    
    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    print("\nüí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
    if not results.get("environment"):
        print("  ‚Ä¢ –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–∞–π–ª .env –∏ —Ñ–æ—Ä–º–∞—Ç API –∫–ª—é—á–∞")
    if not results.get("basic_api"):
        print("  ‚Ä¢ –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –∏ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å –∫–ª—é—á–∞")
    if not results.get("models"):
        print("  ‚Ä¢ –í–æ–∑–º–æ–∂–Ω–æ, —É –≤–∞—Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–π –¥–æ—Å—Ç—É–ø –∫ API")
    if not results.get("langchain"):
        print("  ‚Ä¢ –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ langchain-openai –¥–ª—è –ø–æ–ª–Ω–æ–π –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üöÄ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï OPENAI API")
    print(f"–í—Ä–µ–º—è –∑–∞–ø—É—Å–∫–∞: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    results = {}
    
    try:
        # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è
        api_key = test_environment()
        results["environment"] = api_key is not None
        
        if not api_key:
            print_status("–î–∞–ª—å–Ω–µ–π—à–µ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ –±–µ–∑ API –∫–ª—é—á–∞", "error")
            generate_report(results)
            return
        
        # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫
        results["libraries"] = test_openai_import()
        
        if not results["libraries"]:
            print_status("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –±–∏–±–ª–∏–æ—Ç–µ–∫—É OpenAI –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è", "error")
            generate_report(results)
            return
        
        # 3. –ë–∞–∑–æ–≤—ã–π —Ç–µ—Å—Ç API
        results["basic_api"] = test_basic_api_call(api_key)
        
        # 4. –¢–µ—Å—Ç –º–æ–¥–µ–ª–µ–π (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –±–∞–∑–æ–≤—ã–π —Ç–µ—Å—Ç –ø—Ä–æ—à–µ–ª)
        if results["basic_api"]:
            results["models"] = test_models_availability(api_key)
            results["embeddings"] = test_embeddings(api_key)
            results["rate_limits"] = test_rate_limits(api_key)
        else:
            results["models"] = False
            results["embeddings"] = False
            results["rate_limits"] = False
        
        # 5. –¢–µ—Å—Ç LangChain (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        results["langchain"] = test_langchain_integration(api_key)
        
    except KeyboardInterrupt:
        print_status("\n–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º", "warning")
    except Exception as e:
        print_status(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}", "error")
        traceback.print_exc()
    
    finally:
        generate_report(results)

if __name__ == "__main__":
    main()